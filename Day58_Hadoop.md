## **HADOOP DOCS**
​
 1. hadoop main docs
​
     : [https://hadoop.apache.org/docs/r2.10.1/](https://hadoop.apache.org/docs/r2.10.1/) 
​
2. hadoop reference docs 
​
     : [https://hadoop.apache.org/docs/r2.10.1/api/index.html](https://hadoop.apache.org/docs/r2.10.1/api/index.html) 
​
**설치 종류**
​
General →  Single Node Setup → 한대 만 설치 → 리눅스 설치  
                Cluster Setup → 여러 대 설치 , 하둡 설치 시 사용?
​
   **하둡 기초**
​
  General  → HDFS (Architecture) → MapReduce  → YARN   
   
   
    1) org.apache.hadoop // org.apache.hadoop.HadoopIllegalArgumentExceptio  
       : 하둡 사용시 에러 → 확인 
​
    2) org.apache.hadoop.fs : 하둡 파일 업, 다운로드  
        
    3) org.apache.hadoop.io   
      
    4) org.apache.hadoop.mapreduce         
​
### **Data**
​
 현실에서 관찰이나, 측정을 통해서 수집된 사실(fact) 나 값(value) 를 말한다.
​
### **information**
​
 데이터의 유효한 해석이나 데이터 상호간의 관계를 의사 결정에 도움이 되도록 가공
​
## **DataBase**
​
 여러 응용 시스템들이 공유 할 수 있도록 통합, 저장된 운영 데이터 집합
​
### **Database Management System (DBMS)**
​
모든 응용 프로그램들이 데이터 베이스를 공유할 수 있도록 관리해주고, 데이터 베이스를 유지하기 위한 일련의 소프트 웨어 시스템
​
## **Bigdata**
​
부피가 크고, 변화의 속도가 빠르며, 데이터 속성이 다양한 데이터를 의미
​
속도, 다양성, 용량 조건이 충족 되어야 빅 데이터라고 볼 수 있음
​
 **1. Volume (크기)**
​
    :  수십개의 TB ~ PB, 분산 컴퓨팅 기법으로 데이터를 저장, 분석 해야함
​
     - 솔루션  : 구글의 GFS, 아파치의 하둡
​
 **2. Velocity (속도)**
​
   : 빠른 속도로 생성되는 디지털 데이터를 처리하기 위해 실시간으로 데이터를 생산, 저장, 유통, 수집, 분석 처리해야함
​
    -  수집된 대량의 데이터를 장기적이고 전략적인 차원에서 접근하여 분석해야함
​
    -  데이터 마이닝, 기계학습, 자연어 처리, 패턴 인식등을 활용
​
    -  실시간 처리 (디지털 데이터, 빠른 생산속도, 생성, 저장, 유통, 수집 분석, 실시간 처리요구)
​
    -  장기적인 접근
​
      (다양한 분석 기법 및 표현 기술, 장기적이며 전략적인 차원 고려, 데이터 마이닝, 기계 학습,
​
        자연어 처리, 패턴 인식)
​
 **3. Variety (다양성)**
​
    **: 정형데이터**
​
   - 고정된 필드에 저장되는 데이터, 데이터 베이스의 테이블 구조, 일정한 형식,
​
     기존 솔루션도 이용 쉽게 보관, 분석, 처리 작업 가능 
​
    **: 반정형 데이터**
​
  - 고정된 필드는 아니나 형식은 존재, xml, html, json 같이 메타 데이터나 스키마 등을 포함하는 데이터,
​
    파일 기반이 대부분 
​
    **: 비정형 데이터**
​
 -  고정된 필드 없음, 인터넷 상에서 발생하는 sns데이터, 동영상, 웹 사이트 로그파일, 위치정보, 통화 내용 등
​
     비정형 데이터 처리가 빅데이터 처리의 핵심 
​
**4\. Veracity (정확성)**
​
  : 데이터의 불확실성 (본직적으로 불확실한 데이터 유형의 신뢰성과 예측성 관리)
​
  - 분석에 쓰인 데이터의 신뢰관계 (오류와 부정확한 데이터의 처리, 분석 목적과 다른 데이터의 처리)
​
  - 입력데이터의 검증이 필요 (Garbage in, Garbage out)
​
## **Bigdata 프로세스**
​
데이터 이해 (데이터수집),  데이터 처리 (저장/처리), 데이터 변환(통계/표현/통합)
​
  **1단계**
​
     : 데이터 수집기술 - 분산데이터 수집시스템
​
  **2단계**
​
     : 데이터 저장, 처리기술 - 데이터 저장/관리 기술, 데이터 처리/분석 기술
​
  **3단계**
​
    : 통계/표현/통합기술 - 통계컴퓨팅, 데이터시각화/인터페이스, 워크플로우/데이터 통합
​
## **GFS & MAPREDUCE**
​
**신뢰성 요구 사항**
​
 : 장애에 대한 고립
​
 -  부분적인 장애 발생 시 애플리 케이션의 일부 성능 저하는 발생할 수 있지만 시스템 전체가 중단되는 일은 없어야함
​
 : 데이터 장애의 복구
​
  - 일부 데이터 장애가 발생하더라도, 다른 정상적인 데이터에 의해 작업이 수행됨
​
 : 멤버 노드의 재시작 
​
  - 특정 노드가 실패 후 재시작 될 경우 전체 클러스터 재시작 없이 클러스터 Activity에 다시 참여할 수 있어야함
​
 : 선형적인 확장성
​
  - 시스템에 부하를 가중시킬 지라도 장애가 아닌 자연스러운 성능저하로 이어져야 함
​
    리소스 증가량에 비례해서 더 많은 부하를 처리할 수 있어야함
​
**급진적인 아키텍쳐**
​
 - 노드들간 상호 통신을 최소화 하거나 없앰 (비 공유 아키텍쳐)
​
 - 개발자들이 노드들간의 상호 통신을 명시적으로 할 수 없도록 설계 함
​
 - 데이터는 서버들에 미리 분배 되어 있어야 하며, 컴퓨팅이 데이터가 있는 곳에서 일어 나야함
​
**데이터 지역성**
​
 : 마스터는 데이터의 위치에 기반하여 테스크(history)를 스케줄링
​
   - 물리적인 파일이 있는 머신이나 Rack에 map 테스크 할당을 시도함
​
 : Map 테스크 입력 파일은 64~128MB 의 블록으로 나누어짐 
​
  - 파일 시스템의 Chunk와 동일한 크기
​
    병렬로 하나의 파일의 Chunk들을 처리
​
**고장 감내성**
​
 - 모든 테스트 들은 독립적으로 실행 됨
​
 - 마스터는 워커의 실패 상황을 감지
​
 - 실패시 실패한 테스크들을 재 실행함
​
 - 테스크가 재 시작하더라도 다른 테스크들과 통신할 필요 없음
​
 - 데이터는 안정과 신뢰성을 높이기 위해서 여러 노드에 복제됨
​
**성능 저하 방식**
​
  : Reduce는 map이 끝날 때 까지 시작 안됨 
​
   - 하나의 느린 디스크 컨트롤러가 전체 작업 프로세스를 지연 시킬 수 있음
​
 : 마스터는 여러 개의 동일한 map 을 실행 시킬 수 있음
​
   - 복제 본들 중 처음 끝나는 map의 결과를 취함
​
   - Speculative rask execution
​
즉, 대용량 데이터를 위한 컴퓨팅은 이전과는 근본적인 다른 접근 방법이 필요함
​
  GFS와 MapReduce는 데이터 중심의 새로운 문제 해결 방식 (Hadoop프로젝트의 동기가 됨)
​
## **Hadoop**
​
 **대용량 데이터**를 분산 처리 할 수 있는 자바 기반의 오픈소스 프레임워크
​
 - 분산 파일 시스템인 **HDFS**에 데이터를 저장하고 분산처리 시스템인 **맵리듀스**를 이용해 데이터 처리
​
 - 데이터의 복제본을 저장하기 때문에 데이터의 유실이나 장애가 발생했을 때도 데이터의 복구가 가능함
​
✔ 정형데이터 : RDBMS저장 (RDBMS는 라이센스 비용이 비쌈)
​
 - RDBMS : 데이터가 저장된 서버에서 데이터를 처리
​
✔ 비정형데이터 (사이즈 큼) → Hadoop저장
​
 - 하둡 : 여러 대의 서버에 데이터를 저장하고, 데이터가 저장된 각 서버에서 동시에 데이터를 처리
​
하둡은 기존 RDBMS를 대체하지 않는다. 오히려 RDBMS와 상호 보완적 특성을 가짐
​
하둡은 ETL (Extraction, Transformation, Loading) 과정에 도움을 줌 
​
  - ETL : 자체적으로 쉘 스크립트나 SQL문을 이용해 진행하거나, Data Stage같은 상용 솔루션을 이용해 진행
​
하둡은 SQL언어를 사용할 수 있다. (Hive에서 HiveQL이라는 쿼리 언어 제공)
​
**NoSQL**
​
 - 관계형 데이터 모델과 SQL문을 사용하지 않는 데이터 베이스 시스템 혹은 데이터 저장소
​
 - 단순히 키와 값의 쌍으로만 이뤄져 있음
​
 - 인덱스와 데이터가 분리되어 별도로 운영됨
​
 - 조인 없음
​
 - 데이터를 하나의 집합된 형태로 저장
​
 - Sharding : 데이터를 분할 해서 다른 서버에 나누어 저장
​
**RDBMS**
​
\- 엔티티 간의 관계에 중점을 두고 테이블 구조를 설계하는 방식
​
\- 데이터가 여러 행(row)으로 존재함
​
\- 핵심데이터 관리(데이터 무결성과 적합성 제공)
​
Hadoop의 응용분야
​
 : ETL, Data Warehouse, Storage for Log Aggregator 등
​
## **Hadoop Ecosystem**
​
비즈니스에 효율적으로 적용하기 위한 하둡의 다양한 서브프로젝트 
​
✔ **Zookeeper (분산 코디네이터)**
​
  : Zookeeper란 ? 서버를 홀수 대로 묶어서 관리 , 앙상블 기법을 이용해 순수 관리만 함
​
   (관리를 너무잘함, 한대가 이상이 있으면 작동하지 않음)
​
  분산 환경에서 서버 간의 상호조정이 필요한 다양한 서비스를 제공하는 시스템 
​
  - 하나의 서버에만 서비스가 집중되지 않게 서비스를 알맞게 분산해 동시에 처리하게 해줌 
​
  - 하나의 서버에서 처리한 결과를 다른 서버와도 동기화 해서 데이터의 안정성을 보장해 줌
​
  - 운영 서버가 문제가 발생해서 서비스를 제공할 수 없을 경우, 다른 대기 중인 서버를 운영 서버로 바꿔서 서비스가 중지 없게 제공 되게함 
​
  - 분산 환경을 구성하는 서버들의 환경 설정을 통합적으로 관리
​
    (Heartbeat 역할??)
​
 **✔ Oozie (워크 플로우 관리)**
​
 : 전체 파이프라인을 통해 플로우를 제어, 지정하는 것 (너무 관리를 잘하기 때문에 버전이 맞지않으면 작동하지 않음) 
​
  - 하둡 작업을 관리하는 워크 플로우 및 코디네이터 시스템
​
  - 자바 서블릿 컨테이너에서 실행되는 자바 웹 어플리 케이션 서버
​
  - 맵리 듀스 작업이나 피그(데이터분석) 작업 같은 특화된 액션으로 구성된 워크 플로우를 제어
​
 **✔ Hbase (분산 데이터 베이스)**
​
 : 데이터 분산시스템
​
   -  HDFS 기반의 칼럼 기반 데이터 베이스
​
   - 실시간 랜덤 조회 및 업데이트 가능
​
   - 각 프로세스는 개인의 데이터를 비 동기적으로 업데이트 
​
   - 단, 맵리듀스는 일괄 처리 방식으로 수행됨
​
**✔ 비정형 데이터 수집  (Chukwa, Flume, Scribe)**  
​
    ecosystem - 4대가 한대로 묶여있음
​
 **Chukwa** 
​
  : 분산 환경에서 생성되는 데이터를 HDFS에 안정적으로 저장하는 플랫폼
​
  - 분산된 각 서버에서 에이전트를 실행하고, 콜렉터가 에이전트로 부터 데이터를 받아 HDFS에 저장
​
  - 콜렉터는 100개의 에이전트당 하나씩 구동
​
  - 데이터 중복 제거 등 작업은 맵리듀스로 처리
​
  - Chukwa를 머신 설치하고 다른 피시에 또 설치할수있다.
​
 **Flume**
​
   : Chukwa처럼 분산된 서버에 에이전트가 설치되고, 에이전트로 부터 데이터를 전달 받는 콜렉터로 구성
​
   - 전체 데이터의 흐름을 관리하는 마스터 서버가 있음
​
   - 즉, 데이터를 어디서 수집, 어떤 방식으로 전송, 어디에 저장할 지를 동적으로 변경 할 수 있음 
​
 **Scribe** 
​
   : 데이터 수집 플랫폼
​
   - 데이터를 중앙 집중 서버로 전송
​
   - 최종 데이터는 HDFS 외 다양한 저장소를 활용 할 수 있음
​
   - 설치와 구성이 쉽도록 다양한 프로그래밍 언어를 지원, HDFS에 데이터 저장을 위해 JNI이용해야함 
​
**✔ 정형 데이터 수집 (Sqoop, Hiho)**
​
 **Sqoop**
​
   : 대용량 데이터 전송 솔루션
​
   -  HDFS, RDbMS, DW, NoSQL 등 다양한 저장소에 대용량 데이터를 신속하게 전송할 수 있는 방법 제공
​
   -  상용 RDBMS도 지원하고, MySQL, PostgreSQL 오픈소스 RDBMS 도 지원함
​
 **Hiho**
​
  : 대용량 데이터 전송 솔루션
​
  -  하둡에서 데이터를 가져오기 위한 SQL을 지정할 수 있음
​
  -  JDBC 인터페이스 지원
​
  -  오라클과 MySQL의 데이터 전송 만 지원 함 
​
**✔ 데이터 분석 (Pig, Hive)**
​
   **Pig**
​
   :  복잡한 맵리듀스 프로그래밍을 대체한 Pig Latin이라는 자체 언어 제공
​
   -  맵리듀스 API를 크게 단순화 함
​
   -   SQL과 유사한 형태, 단 SQL활용이 어려운 편
​
   **Hive** (데이터 엔지니어가 많이 함)
​
   :  데이터웨어하우징용 솔루션
​
   -  SQL과 매우 유사한 HiveQL 쿼리 제공 (내부적으로 맵리듀스 잡으로 변환되어 실행 됨)
​
   - 자바를 모르는 데이터 분석가들도 쉽게 하둡 데이터를 분석할 수 있게 도와줌
​
   - 짧은 임시 쿼리보다 일괄적인 MapReduce 처리에 이상적임
​
**✔ 데이터마이닝 (Mahout) → 여기까지가 머신러닝**
​
  : 하둡 기반으로 데이터 마이닝 알고리즘을 구현하였음
​
   - 분류, 클러스터링, 추천 및 협업 필터링, 패턴 마이닝, 회귀 분석, 차원 리덕션, 진화 알고리즘 
​
**✔ 메타데이터 관리 (Hcatalog)**
​
  : 하둡으로 생성한 데이터를 위한 테이블 및 스토리지 관리 서비스
​
  - 하둡 에코 시스템 간의 상호 운용성 향상에 큰 영향 
​
  - Hcatalog 의 이용으로 Hive에서 생성한 테이블이나 데이터 모델을 Pig나 맵리듀스에서 손쉽게 이용할 수있음 
​
**✔ 직렬화 (Avro)**
​
   : RPC 와 데이터 직렬화를 지원
​
   - JSON을 이용해 데이터 형식과 프로토콜을 정의
​
   - 작고 빠른 바이너리 포맷으로 데이터를 직렬화
​
## **HDFS (Hadoop Distributed File System)**
​
 - google 의 GFS 기반
​
 - 저사양 서버를 이용해 스토리지를 구성할 수 있음
​
 - 대규모 데이터를 저장, 배치로 처리하는 경우
​
 - 대용량 파일을 분산된 서버에 저장하고 많은 클라이언트가 저장된 데이터를 빠르게 처리할 수 있게 설계 된 파일 시스템
​
DAS : 서버에 직접 연결된 스토리지
​
        여러개의 하드 디스크를 장착할 수 있는 외장형 하드 디스크 
​
NAS : 파일 시스템을 안정적으로 공유할 수 있음
​
        별도의 운영체제 사용
​
SAN : 수십- 수백대의  SAN 스토리지를 데이터 서버에 연결해 총괄적으로 관리해주는 네트워크
​
        DBMS와 같이 안정적으로 빠른 접근이 필요한 데이터를 저장하는데 사용 (고성능, 고가용성)
​
**목적**
​
1\. 장애 복구
​
  : 디스크 오류로 인한 데이터 저장 실패 및 유실과 같은 장애를 빠른 시간에 감지하고 대처
​
    데이터 저장하면 복제 데이터도 함께 저장 해서 데이터 유실을 방지함
​
    분산 서버 간 주기적인 상태 체크
​
2\. 스트리밍 방식의 데이터 접근
​
  : HDFS에 파일 저장 및 조회를 위해 스트리밍 방식으로 데이터에 접근 해야함
​
   배치 작업 과 높은 데이터 처리량을 위해 스트리밍 방식 사용
​
3\. 대용량 데이터 저장
​
  : 하나의 파일이 GB ~ TB이상의 사이즈로 저장 될 수 있게 설계
​
   높은 데이터 전송 대역폭, 하나의 클러스터에서 수백대의 노드를 지원
​
   하나의 인스턴스에서 수백만 개 이상의 파일을 지원
​
4\. 데이터 무결성
​
   : Immutable 파일 , 한번 저장한 데이터를 수정할 수 없음 (읽기만 가능)
​
     파일 이동, 삭제, 복사할 수 있는 인터 페이스 제공
​
### **HDFS Architecture**
​
**Marster : NameNode**
​
  - Namespace와 메타데이터 관리
​
**Slave : Datanode**
​
 -  실제 데이터를 저장하는 역할
​
 -  로컬파일 시스템에는 블록이라는 객체들로 파일 내용 저장 
​
## **MapReduce**
​
 - HDFS에 분산 저장된 데이터에 스트리밍 접근을 요청하며 빠르게 분산 처리하도록 고안된 프로그래밍 모델
​
   이를 지원하는 시스템 
​
   → 함수형 프로그래밍 + 분산 컴퓨팅
​
\- 대규모 분산 컴퓨팅 혹은 단일 컴퓨팅 환경에서 개발자가 대량의 데이터를 병렬로 분석 할 수 있음
​
\- 배치 데이터 처리에 적합
​
\- 개발자는 맵리듀스 알고리즘에 맞게 분석 프로그램을 개발하고, 데이터의 입출력과 병렬 처리 등 기반 작업은 프레임 워크가 알아서 처리해줌 
​
  (자동적인 병렬화와 분산, 장애에 대한 고민 제거, 상태 정보와 관리 도구 제공)
​
**Map : (k1, v1) → list(k2, v2)**
​
        데이터를 가공해서 분류 (연산 가공자)
​
**Reduce : (k2, list(v2)) → list(k3, v3)**
​
        분류된 데이터를 통합(집계 연산자)
​
     방식 : HDFS → Map → Shuffle → Reduce → Result
​
※ 각각의 머신은 Map 과 Reduce 작업을 한다.
​
  marster = namenode가 잡트래커를 가지고 있다. (맵이 정상적으로 작동하는 지를 태스크 트래커를 통해 알고있다)
​
### **MapReduce Architecture**
​
**클라이언트**
​
  맵리듀스 프로그램 & API
​
**잡트래커 (네임노드 서버에서 실행)**
​
  맵리듀스 프로그램은 job이라는 하나의 작업 단위로 관리됨
​
  하둡 클러스터에 등록된 전체 잡의 스케줄링을 관리하고 모니터링
​
    → (사용자가 새로운 잡을 요청하면 잡 트래커는 잡을 처리하기 위해 몇 개의 맵과 리듀스를 실행할 지 계산, 어떤 태스크 트래커에서 실행할지 결정, 잡 할당)
​
  전체 클러스터에서 하나의 잡트래커가 실행
​
**태스크트래커 (데이터 노드에서 실행)**
​
  잡트래커의 작업 수행 요청을 받아 맵리듀스 프로그램 실행
​
  잡트래커가 요청한 맵과 리듀스 갯수만큼 맵, 리듀스 태스크를 생성
​
  새로운 JVM을 구동해 맵, 리듀스 태스크 실행
​
    → (이 때 JVM은 재사용 할 수 있게 설정 가능, 데이터 노드가 하나라도 여러개의 JVM을 실행해서 데이터를 동시에 분석함 = 병렬 처리가능)
​
※ 입력 스플릿 (input split)
​
\- 하나의 맵에서 처리해야 하는 입력 파일의 크기
​
\- 하둡은 맵리듀스 잡의 입력 데이터를 입력 스플릿이라는 고정된 크기의 조각으로 분리
​
\- 생성된 입력 스플릿 마다 맵 태스크를 하나씩 생성
​
\- 기본 설정 64MB로 입력 스플릿이 생성됨 (HDFS의 기본 블록 사이즈0
​
## **Hadoop 2.0 , Yarn**
​
Hadoop 1.0 단점 
​
 - 한노드에서 실행 할 수 있는 Map 과 Reduce용 작업 숫자가 제한되어 노드에 여유 자원이 있어도 그 자원을 활용하지 못하는 상황 발생
​
 - 자원 분배 및 작업 관리 비효율 성
​
**Yarn (Yet Another Resource Negotiator)**
​
 - 자원관리, Job 상태 관리를 ResourceManager와 ApplicationMaster로 분리하여 기존 Job Tracker에 몰리던 병목을 제거
​
\- MapReduce외 다양한 어플리케이션을 실행할 수 있으며 어플리케이션 마다 자원(CPU, 메모리)을 할당받음
